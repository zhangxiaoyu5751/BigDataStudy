# python

## 闭包
### 闭包概念
我理解的闭包就是在一个函数体内还有另外一个子函数，当子函数使用到了父函数的变量，那么就可以称作为闭包。
所以闭包函数的特点为：
- 闭包函数必须有内嵌函数
- 内嵌函数必须引用该内嵌函数上一级的变量
- 闭包函数必须返回内嵌函数
### 闭包的作用以及使用场景
我理解为，闭包虽然是函数式编程，但是其实类似于一个简单的面向对象编程思想，

- 首先可以基于上次计算的结果进行继续计算，保持住当前的运行环境。保存函数的状态信息，使函数的局部变量信息依然可以保存下来。类似于更改类对象中的self变量
```python
def func(step):
    num = 1

    
    def func2():
        nonlocal num
        num = num + step
        print num
    return func2

j =  1
a = func(3)
while j < 5:
    a()
    j += 1
```

- 装饰器

- 闭包可以根据外部作用域的局部变量来得到不同的结果。很好的把不同对象用同一个函数处理后的数据进行整理归类。类似于工厂模式
```python
def grade(str1):
    print '你的成绩是：'
    def func1(str2):
        print str1 + str2
    return func1
a = grade('小李')
a('语文118')
b = grade('小红:')
b('数学120')
```


## 装饰器
### 装饰器的概念
装饰器 就是在函数不需要做任何代码修改的前提下增加额外的功能。

```python
def use_logging(level):
    def decorator(func):
        def wrapper(*args, **kwargs):
            if level == "warn":
                logging.warn("%s is running" % func.__name__)
            elif level == "info":
                logging.info("%s is running" % func.__name__)
            return func(*args)
        return wrapper

    return decorator

@use_logging(level="warn")
def foo(name='foo'):
    print("i am %s" % name)

foo()
```
上面是一个有参数的装饰器的例子。

同时，为了保证原函数的元信息，则使用functools.wraps来装饰最里面的函数。来保证函数的docstring __name__ 是原函数的信息

```python
@a
@b
@c
def f():
    pass
```
执行顺序，从里到外。先执行c 然后是b 然后是a


## python 多进程和多线程

### python有了GIL，为什么还需要加锁呢？
线程的同步和互斥是解决的线程之间数据访问的正确性的问题，而GIL 是实现的当前解释器下只有一个线程执行，是不同的概念。
gil控制的是字节码
线程AB同时操作listlist的[0]初始值为0线程A 操作100次list[0]+=1线程B 操作100次list[0]+=1在线程A 对于 list[0]进行操作时list[0]为0, 还没等线程A完成加一操作, 就被切换到线程B了在线程B 眼里,list[0]还是为0, 于是执行加一操作.再切换回线程A, 继续未完成的加一操作你发现了没!!! 线程AB各对list[0]进行了加一,预期结果是2 但结果还是1

### python 多进程
进程是正在执行的计算机程序的实例。每一个进程提供执行程序所需要的所有资源。一个进程有虚拟的地址空间，可执行的代码，环境变量，内存空间，至少还要有一个进程。

每一个进程启动的时候都会最先启动一个线程，就是主线程，然后主线程会创建其他的子线程。
### python 多线程

线程是操作系统能够进行运算调度的最小单位，线程是包含在进程之中，是进程实际运作的单位。一条线程指的是进程中一个单一顺序的控制流。一个进程可以并发多个线程。每条线程执行不同的任务。


### python多进程和多线程的区别
- 同一个进程中的线程是共享内存空间的，但是进程之间是独立的
- 同一个进程的所有线程的数据是共享的，进程之间的数据是独立的
- 同一个进程的线程之间是可以直接通信的，但是进程之间的交流需要中间代理
- 对主线程修改可能影响到其他线程，但是父进程的修改不会影响到其他子进程
- 创建新的线程很容易，但是创建新的进程需要对父进程进行复制
- 线程启动速度快，进程启动速度慢

### GIL 
谈到python多线程的话，就离不开的一个话题就是GIL。全局解释锁。在解释器的主循环中，只能由一个线程在执行。python解释器可以运行多个线程，但是在给定时刻只有一个线程会被解释器执行。
在python多线程下，每个线程的执行方式:
- 获取GIL
- 执行代码知道sleep或者是达到了GIL 释放的条件
- 释放GIL
- 进而由其他进程重复上面的过程
- 等其他进程执行完后，又会切换到之前的线程（从他记录的上下文继续执行）
整个过程是每个线程执行自己的运算，当执行时间到就进行切换（context switch）。

也就是说，某个线程想要执行，必须先拿到GIL，每一个进程GIL 只有一个，拿不到GIL 的线程是不允许执行的。

在Python2.x里，GIL的释放逻辑是当前线程遇见IO操作或者ticks计数达到100（ticks可以看作是Python自身的一个计数器，专门做用于GIL，每次释放后归零，这个计数可以通过 sys.setcheckinterval 来调整），进行释放。
而每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源。并且由于GIL锁存在，python里一个进程永远只能同时执行一个线程(拿到GIL的线程才能执行)，这就是为什么在多核CPU上，python的多线程效率并不高。

在python3.x中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。

### 多进程多线程使用建议
1. cpu密集型代码，在这种情况下，计算工作比较多，ticks技术很快达到阈值，然后释放GIL 竞争，所以多线程对于cpu密集型并不友好，推荐使用多进程
2. io密集型，多线程能够提高效率，开启多线程后，线程a等待的时候自动切换线程b，可以不浪费CPU 资源。建议使用多线程。

### python 协程



## python 垃圾回收机制

python的垃圾回收机制分为以下三点：引用计数/标记-清除/分代回收

### 引用计数

在python中，每一个对象的核心就是一个结构体pyobject，他的内部都有一个引用计数器
```c
typedef struct_object{
    int ob_refcnt;
    struct_typeobject *ob_type;
} Pyobject;
```

引用计数的意思就是，一个对象在他刚开始被创建出来的时候，因为是被new方法引用，所以他的引用计数就是1，如果被引用，这个引用计数就会加一，如果引用他的对象被删除的时候，那么他的引用计数就会减少，知道他的引用计数变为0 的时候，垃圾回收机制就会把他回收掉

引用计数的优点：
    简单，实时性
缺点：
    维护性高(简单实时，但是会额外占用一部分资源)，同时会有一部分无法解决的情况 ==》循环引用问题
```python
a = [1,2]
b = [2,3]
a.append(b)
b.append(a)
del a
del b
```
这种问题出现在可以循环的结构当中，就像上面代码，a，b之间的引用都是1，然后追加之后都变成2，当引用的对象删除后 各自减去1，所以最后就变成1，这样就一直是1 不会发生变化了，这样情况靠引用计数无法解决，于是引入了标记删除的概念。

### 标记-清除
标记清除使用来解决循环引用的问题的只有容器对象才会出现的引用循环，比如列表，字典，类，元组等。首先，为了追踪容器对象，需要为每个容器对象维护两个额外的指针，用来将容器对象组成一个链表，指针分别指向前后两个容器对象，方便插入和删除操作。

在标记清除算法中，有两个链表，一个是root链表，一个是unreachable链表。

当出现循环引用的时候， 标记清除算法开始拆引用的环，吧引用数减1，这样就完成了循环引用对象间环的摘除。去掉之后，如果引用计数变成0，那么久放到unreachable链表当中。

如果只是删除其中的一个链表，他的引用计数为0，但是引用他的没有删除，就还是1，这样的话 就把链表从unreeachable中移出到root链表中

#### 为什么要两个链表：
之所以用两个链表，是因为 现在的unreachable链表当中可能存在被root链表中的对象直接或者间接引用的对象，这些对象是不能被回收的，一旦在标记的过程中，发现这样的对象，就把他们从unreachable链表中移到root链表中，当完成标记后，unreachable链表中剩下的所有对象就是垃圾对象了，接下来的垃圾回收只需要限制在unreachable链表中就可以。

### 分代回收

随着程序的运行，python解释器保持创建新的对象，以及因为引用计数为0而被释放掉的对象的追踪。从理论上来说，创建==释放。但是如果存在循环引用的话，肯定是创建 > 释放。当创建和释放的数量的的差值达到阈值之后，就有了分代回收机制。

在循环引用对象的回收过程中，整个程序会被暂停，为了减少应用程序暂停时间，python通过分代回收以空间换时间的方法提高垃圾回收效率。

垃圾回收= 垃圾检测 + 释放

分代回收思想是把对象分成三代(generation 0， 1， 2)，0代表幼年对象，1代表青年对象，2代表老年对象。根据弱代假说(越年轻的对象越容易死掉，老的对象通常会存活更久)，新生的对象被放入0代。如果该对象在第0代的一次gc回收中活了下来，那就把它放到第一代里面，如果在第一代里面的对象在第一次gc垃圾回收中活了下来，就把他放到第二代里面。gc.set_threshold(threshold0, [threshold1,[threshold2]]) 可以设置每一代垃圾回收所触发的阈值。从上一次第0代gc后，如果分配对象个数减去释放对象个数大于threshold0，就会对第0代对象进行gc垃圾回收检查，从上一次第1代gc后，如过第0代被gc垃圾回收的次数大于threshold1，那么就会对第1代中的对象进行gc垃圾回收检查。同样，从上一次第2代gc后，如过第1代被gc垃圾回收的次数大于threshold2，那么就会对第2代中的对象进行gc垃圾回收检查。

https://juejin.im/post/5b34b117f265da59a50b2fbe

https://zhuanlan.zhihu.com/p/83251959


